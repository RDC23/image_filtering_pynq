{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf561d7",
   "metadata": {},
   "source": [
    "# Fully Customisable 3x3 Filter\n",
    "\n",
    "This notebook demonstrates how PYNQ can be used to communicate with an overlay to execute a custom 3x3 image filter, or select from a number of included kernels. Kernels can be fully customised using widgets to set the filter weights, and an optional normalisation value can be specified to control the brightness of the filtered image.\n",
    "\n",
    "A pre-generated bitstream (.bit) and hardware handoff file (.hwh) are used to interface Python with the hardware programmable logic on Pynq. If desired, these files can be re-created using MATLAB System Generator to open `General_Filter.slx` model and then Vivado to create the IP. The required connections are shown in the Figure below.\n",
    "\n",
    "![IP Integrator diagram for the Sobel Filter example](./assets/IP.png)\n",
    "  \n",
    "  > The names of the DMA IP cores are important (specifically, general_filer_0) here as we use these names from Python later on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9728b",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries for the project. The Python Image library provides adds support for opening, manipulating and modifying image data across a range of supported file formats. Image data is represented using a multidimensional array of pixels. Therefore, standard array operations such as slicing and addition form the basis for many image processing tasks. Compared with Python's native list data structure, numpy arrays are more memory efficient and provide faster execution of numerical operations due to their contiguous memory layout and optimized C implementation. The other libraries provide support for interactive widgets and allow users to upload files to the notebook using an intuitive GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f86992",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwidgets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811f2bb",
   "metadata": {},
   "source": [
    "Use the ''Upload'' button below to select an image you wish to apply some filters to. We recommend using either .png or .jpg files for best results. The PIL library comes in useful here to load the image data into the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3e845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324f05ad121f42b3ad76b0a22208deaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.png', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload = widgets.FileUpload(\n",
    "    accept='.png',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False  # True to accept multiple files upload else False\n",
    ")\n",
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, file_info in upload.value.items():\n",
    "    image_raw = Image.open(io.BytesIO(file_info['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfa348",
   "metadata": {},
   "source": [
    "To filter an image, a mathematical operation known as convolution is used. In convolution, an $n \\times n$ matrix (Kernel) with impulse response $h[n,m]$ is convolved with the image data $f[n,m]$ to produce an activation heatmap, $y[n,m]$, representing the filtered image. This operation is expressed mathematically in Equation 1.\n",
    "\n",
    "\\begin{equation}\n",
    "    y[n,m] = \\sum_{k_1=-\\infty}^{\\infty} \\sum_{k_2=-\\infty}^{\\infty} f[k_1,k_2] \\cdot h[n-k_1, m-k_2]\n",
    "\\end{equation}\n",
    "\n",
    "The choice of kernel weights determines the result of the filter. The dropdown widget below can be used to select from some popular kernels, including a Gaussian Blur and Sharpen kernel.\n",
    "\n",
    "To realise this filter in hardware, the System Generator Model shown below was used. Note how the multiply-accumulate operations in Equation 1 are reflected in hardware using the CMult and Add blocks in along a carry \"chain\" along the top of the model. The critical path is very long, so cut-set retiming was used to facillitate an increase in clock speed. To do this, $z^{-1}$ blocks were inserted in columns thus delaying all signal paths. \n",
    "\n",
    "![2D Convolution Implemented In Hardware](./assets/matlab_simulink_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ce3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f558b10d471448cc9a8b35075457a87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Filter: ', options=(('Sobel', [-1, 0, 1, -2, 0, 2, -1, 0, 1, 1]), ('Sharpen', [0, -1, 0,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropdown = widgets.Dropdown(options = [(\"Sobel\",[-1,0,1,-2,0,2,-1,0,1,1]),\n",
    "                                       (\"Sharpen\",[0,-1,0,-1,5,-1,0,-1,0,1]),\n",
    "                                       (\"RidgeDetection\",[0,-1,0,-1,4,-1,0,-1,0,1]),\n",
    "                                       (\"BoxBlur\",[1,1,1,1,1,1,1,1,1,9]),\n",
    "                                       (\"GaussianBlur\",[1,2,1,2,4,2,1,2,1,16])\n",
    "                                      ],description = \"Filter: \")\n",
    "dropdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08740b0d",
   "metadata": {},
   "source": [
    "Next, we need to do some pre-formatting of the image data by selecting the RGB channels and formatting the image as a 1920 by 1080 picture. Do not be alarmed if the image looks a bit stretched! This is normal and is required to make the image data compatibile with the buffer sizes chosen in the IP which was designed. We then cast the image array into a numpy array to enable some efficient matrix operations to be carried out for padding the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937093a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (1920,1080)\n",
    "\n",
    "# Resize and force to RGB colours\n",
    "image = image_raw.resize(IMG_SIZE).convert('RGB')\n",
    "\n",
    "# Interpret as a 3D array of bytes (uint8)\n",
    "image_array = np.array(image, dtype=np.uint8)\n",
    "\n",
    "# Add extra padding on the X and Y dimensions\n",
    "image_array_padded = np.pad(image_array, ((1,1),(1,1),(0,0)), 'symmetric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6496f37",
   "metadata": {},
   "source": [
    "Let's inspect the image which was selected prior to applying any filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(image_array_padded, 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5c7014",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pynq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpynq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Overlay\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpynq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allocate\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#import pynq_sobel\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pynq'"
     ]
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "#import pynq_sobel\n",
    "import os\n",
    "Kernel_Overlay = Overlay(\"general_filter_backup.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed240f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kernel_Overlay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input array for DMA use\n",
    "kernel_in_dma_array  = allocate(shape=(IMG_SIZE[1]+2, IMG_SIZE[0]+2, 4), dtype=np.uint8)\n",
    "\n",
    "# Output array for DMA use\n",
    "kernel_out_dma_array = allocate(shape=(IMG_SIZE[1],IMG_SIZE[0]), dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcda357",
   "metadata": {},
   "source": [
    "The function `do_conv` handles a number of tasks. Firstly, the 'write' method of the Overlay object is invoked to send the kernel weights and optionl normalisation values to the PL using AXI-4 lite. AXI-4 lite is an good, economic choice when modifying registers since this task is low throughput and does not demand high bandwidth utilisation. The weights to pass to the registers are extracted form the Kernel argument of the function. Next, this function copies the image data previously loaded into the DMA buffer and initiates the send and receive channels. Finally, the function waits until the DMA send and receipt of information is complete, before returning the filtered image array to the calling code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf215f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_conv(image_array,Kernel = [0.1, 0, 0, 0, 1, 0, 0, 0, 1], div = 1):\n",
    "    # Set overlay threshold\n",
    "    \n",
    "    Kernel_Overlay.general_filter_0.write(0x20, Kernel[0]) #W00 \n",
    "    Kernel_Overlay.general_filter_0.write(0x1C, Kernel[1]) #W01 \n",
    "    Kernel_Overlay.general_filter_0.write(0x18, Kernel[2]) #W02\n",
    "    Kernel_Overlay.general_filter_0.write(0x14, Kernel[3]) #W10\n",
    "    Kernel_Overlay.general_filter_0.write(0x10, Kernel[4]) #W11\n",
    "    Kernel_Overlay.general_filter_0.write(0x0C, Kernel[5]) #W12\n",
    "    Kernel_Overlay.general_filter_0.write(0x08, Kernel[6]) #W20\n",
    "    Kernel_Overlay.general_filter_0.write(0x04, Kernel[7]) #W21\n",
    "    Kernel_Overlay.general_filter_0.write(0x00, Kernel[8]) #W22\n",
    "    Kernel_Overlay.general_filter_0.write(0x24,       div) #Matrix division\n",
    "    # Copy image array into dma buffer\n",
    "    kernel_in_dma_array[:, :, :3] = image_array[:, :, :]\n",
    "    \n",
    "    Kernel_Overlay.axi_dma.recvchannel.transfer(kernel_out_dma_array)\n",
    "    Kernel_Overlay.axi_dma.sendchannel.transfer(kernel_in_dma_array)\n",
    "\n",
    "    Kernel_Overlay.axi_dma.sendchannel.wait()\n",
    "    Kernel_Overlay.axi_dma.recvchannel.wait()\n",
    "    \n",
    "    return kernel_out_dma_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6965865",
   "metadata": {},
   "source": [
    "The code below extracts the numerical data from the widgets (kernel weights and normalisation factor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f949bc37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dropdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Kernel \u001b[38;5;241m=\u001b[39m \u001b[43mdropdown\u001b[49m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m9\u001b[39m]\n\u001b[0;32m      2\u001b[0m div \u001b[38;5;241m=\u001b[39m dropdown\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m9\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dropdown' is not defined"
     ]
    }
   ],
   "source": [
    "Kernel = dropdown.value[0:9]\n",
    "div = dropdown.value[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931950e",
   "metadata": {},
   "source": [
    "Let's time how long the convolution takes to run on the PL using hardware accleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab7a196",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_array_padded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_array_padded' is not defined"
     ]
    }
   ],
   "source": [
    "%time image_output = do_conv(image_array_padded,Kernel,div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913854a",
   "metadata": {},
   "source": [
    "The code below reconstructs the image from the filtered array sent back from the PL to the PS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d460633",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39muint8(image_output), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(image_output), mode='P')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8c404",
   "metadata": {},
   "source": [
    "Now we will compare the filtering computation using OpenCV to perform the convolution. The kernel weights are extracted from the dropdown widget and then normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8e516b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cvkernel \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([dropdown\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                      dropdown\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      3\u001b[0m                      dropdown\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m8\u001b[39m]])\n\u001b[0;32m      5\u001b[0m cvkernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdivide(cvkernel,dropdown\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m9\u001b[39m])\n\u001b[0;32m      7\u001b[0m img_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image_array, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "cvkernel = np.array([dropdown.value[0:2],\n",
    "                     dropdown.value[3:5],\n",
    "                     dropdown.value[6:8]])\n",
    "\n",
    "cvkernel = np.divide(cvkernel,dropdown.value[9])\n",
    "\n",
    "img_gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679915e",
   "metadata": {},
   "source": [
    "To perform the convolution using OpenCV the `cv2.filter2D` method is employed. The timing results of this computation are shown in the cell outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2184dfec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "%time comp =  cv2.filter2D(img_gray,-1, cvkernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c811e96",
   "metadata": {},
   "source": [
    "For completeness, we will display the filtered image result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
